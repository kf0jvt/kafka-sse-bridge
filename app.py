from kafka import KafkaConsumer
from flask import Flask, Response, send_from_directory
import json
import queue
import threading
import sys
import os
import logging
from dotenv import load_dotenv
from dataclasses import dataclass
from typing import Generator

# Configure a general logger for libraries like KafkaConsumer
# and a custom logger for messages generated by this app
logging.basicConfig(
    level=logging.WARNING, format="%(asctime)s [%(levelname)s] %(funcName)s: %(message)s"
)
log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
numeric_level = getattr(logging, log_level, logging.INFO)
logger = logging.getLogger(__name__)
logger.setLevel(numeric_level)

# Queue to pass messages from Kafka consumer to SSE clients
message_queue = queue.Queue()   

@dataclass
class KafkaConfig:
    consumer_bootstrap_1: list[str]
    consumer_bootstrap_2: list[str]
    kafka_topic: str
    keystore_password: str
    ssl_cert_file: str
    ssl_key_file: str
    ssl_ca_file: str

app = Flask(__name__)

def kafka_consumer_thread(kafka_config: KafkaConfig, broker: int) -> None:
    # Figure out which broker address to use
    bootstrap_servers_to_use = None
    if broker == 1:
         bootstrap_servers_to_use = kafka_config.consumer_bootstrap_1
    if broker == 2:
        bootstrap_servers_to_use = kafka_config.consumer_bootstrap_2
    if not bootstrap_servers_to_use:
        logger.critical("Broker option sent to kafka_consumer_thread was not 1 or 2. No broker address to use. Cannot go on")
        sys.exit(1)

    """Background thread to consume Kafka messages"""
    consumer = KafkaConsumer(
        kafka_config.kafka_topic,
        bootstrap_servers=bootstrap_servers_to_use,
        security_protocol='SSL',
        ssl_certfile=kafka_config.ssl_cert_file,
        ssl_keyfile=kafka_config.ssl_key_file,
        ssl_cafile=kafka_config.ssl_ca_file,
        auto_offset_reset='latest',
        enable_auto_commit=False, # read only connection
        group_id=None,
        value_deserializer=lambda m: m.decode('utf-8')
    )
    
    logger.info(f"Connected to Kafka broker {broker}s, subscribed to topic: {kafka_config.kafka_topic}")
    
    for message in consumer:
        logger.debug(f"Received message: {message.value}")
        # Put message in queue for all SSE clients
        message_queue.put(message.value)

def event_stream() -> Generator[str, None, None]:
    """Generator function for SSE events"""
    while True:
        # Block until a message is available
        message = message_queue.get()
        # Format as SSE
        yield f"data: {message}\n\n"

@app.route('/')
def index() -> Response:
    return send_from_directory('.', 'index.html')

@app.route('/static/<path:filename>')
def static_files(filename: str) -> Response:
    return send_from_directory('static', filename)

@app.route('/events')
def sse() -> Response:
    """SSE endpoint for clients to connect"""
    return Response(event_stream(), mimetype='text/event-stream')

@app.route('/health')
def health() -> Response:
    """Health check endpoint"""
    topic = app.config.get('KAFKA_TOPIC')
    return {'status': 'ok', 'kafka_topic': topic}

if __name__ == '__main__':
    # Load environment from .env file
    load_dotenv()

    # Check for necessary minimum information
    unrecoverable_error = False
    for variable_name in ["CONSUMER_BOOTSTRAP_1", 
                          "CONSUMER_BOOTSTRAP_2", 
                          "KAFKA_TOPIC",
                          "SSL_CERT_FILE",
                          "SSL_KEY_FILE",
                          "SSL_CA_FILE"]:
        if not os.getenv(variable_name, None):
            logger.critical(f"{variable_name} is not found in system ENV or in .env file. Cannot continue")
            unrecoverable_error = True
            continue
        if os.getenv(variable_name) == "":
            logger.critical(f"{variable_name} is set to an empty string. Cannot continue")
            unrecoverable_error = True
    if unrecoverable_error:
        sys.exit(1)

    consumer_bootstrap_1 = os.getenv("CONSUMER_BOOTSTRAP_1").split(",")
    consumer_bootstrap_2 = os.getenv("CONSUMER_BOOTSTRAP_2").split(",")
    kafka_topic = os.getenv("KAFKA_TOPIC")
    keystore_password = os.getenv("KEYSTORE_PASSWORD")
    ssl_cert_file = os.getenv("SSL_CERT_FILE")
    ssl_key_file = os.getenv("SSL_KEY_FILE")
    ssl_ca_file = os.getenv("SSL_CA_FILE")

    # make sure files are present and send a human-understandable error if they are not
    for each_file in [ssl_cert_file, ssl_key_file, ssl_ca_file]:
        if not os.path.exists(each_file):
            logger.critical(f"{each_file} is specified in .env configuration but is not found in this directory. Cannot continue")
            unrecoverable_error = True
    if unrecoverable_error:
        sys.exit(1)

    kafka_config = KafkaConfig(consumer_bootstrap_1, 
                               consumer_bootstrap_2, 
                               kafka_topic,
                               keystore_password, 
                               ssl_cert_file, 
                               ssl_key_file, 
                               ssl_ca_file)

    # Start Kafka consumers in background threads
    # ServiceNow Hermes publishes two consumers and can switch between them
    # For redundancy. We need to monitor both.
    consumer_thread_1 = threading.Thread(target=kafka_consumer_thread, args=(kafka_config,1), daemon=True)
    consumer_thread_1.start()
    consumer_thread_2 = threading.Thread(target=kafka_consumer_thread, args=(kafka_config,2), daemon=True)
    consumer_thread_2.start()
    
    app.config['KAFKA_TOPIC'] = kafka_config.kafka_topic

    # Start Flask server
    print("Starting SSE server on http://0.0.0.0:8000")
    print("Connect to http://localhost:8000/ to receive messages")
    app.run(host='0.0.0.0', port=8000, threaded=True)
